{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 8: Adiciona o método randomized_search_cv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1) Considera a estrutura e algoritmo do randomized_search_cv apresentados nos slides seguintes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2) Valida a tua implementação seguindo o protocolo:\n",
    "\n",
    "1. Usa o dataset breast-bin.csv\n",
    "\n",
    "2. Usa o sklearn.preprocessing.StandardScaler para standardizar os dataset. breast_dataset.X = StandardScaler().fit_transform(breast_dataset.X)\n",
    "\n",
    "3. Cria o modelo LogisticRegression\n",
    "\n",
    "4. Realiza uma procura aleatória com as seguintes distribuições de parâmetros:\n",
    "\n",
    "    • l2_penalty: distribuição entre 1 e 10 com 10 intervalos iguais (e.g., np.linspace(1, 10, 10))\n",
    "\n",
    "    • alpha: distribuição entre 0.001 e 0.0001 com 100 intervalos iguais (e.g., np.linspace(0.001, 0.0001, 100))\n",
    "\n",
    "    • max_iter: distribuição entre 1000 e 2000 com 200 intervalos iguais (e.g., np.linspace(1000, 2000, 200))\n",
    "\n",
    "5. Podes usar n_iter de 10 e 3 folds para o cross_validate.\n",
    "\n",
    "6. Quais os scores obtidos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.io.data_file import read_data_file\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from si.model_selection.cross_validate import cross_validate\n",
    "from si.model_selection.grid_search import grid_search_cv\n",
    "from si.model_selection.randomize_search_cv import randomized_search_cv\n",
    "from si.linear_module.logistic_regression import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': [357, 580, 228, 356, 982],\n",
       " 'train': [0.9653061224489796,\n",
       "  0.9673469387755103,\n",
       "  0.9755102040816327,\n",
       "  0.9734693877551021,\n",
       "  0.9673469387755103],\n",
       " 'test': [0.9760765550239234,\n",
       "  0.9712918660287081,\n",
       "  0.9521531100478469,\n",
       "  0.9569377990430622,\n",
       "  0.9712918660287081],\n",
       " 'parameters': []}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data file to the notebook\n",
    "path = 'C:/Users/Catarina Ferreira/Desktop/Bioinf 2ºano/sistemas_inteligentes/datasets/breast-bin.data'\n",
    "# Reading the data file\n",
    "breast = read_data_file(path, sep=\",\", label=True)\n",
    "\n",
    "# Standardizing and transforming the values\n",
    "breast.x = StandardScaler().fit_transform(breast.x)\n",
    "\n",
    "logistic = LogisticRegression(use_adaptive_alpha=False)\n",
    "# Cross validate the model to get the scores of the model\n",
    "scores = cross_validate(logistic, breast, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'seed': [309, 202, 437],\n",
       "  'train': [0.9693877551020408, 0.9673469387755103, 0.9653061224489796],\n",
       "  'test': [0.9665071770334929, 0.9665071770334929, 0.9760765550239234],\n",
       "  'parameters': [{'l2_penalty': 1, 'alpha': 0.001, 'max_iter': 1000}]},\n",
       " {'seed': [294, 9, 549],\n",
       "  'train': [0.963265306122449, 0.9673469387755103, 0.9653061224489796],\n",
       "  'test': [0.9808612440191388, 0.9712918660287081, 0.9760765550239234],\n",
       "  'parameters': [{'l2_penalty': 1, 'alpha': 0.001, 'max_iter': 2000}]},\n",
       " {'seed': [322, 309, 202],\n",
       "  'train': [0.9734693877551021, 0.9693877551020408, 0.9673469387755103],\n",
       "  'test': [0.9569377990430622, 0.9665071770334929, 0.9665071770334929],\n",
       "  'parameters': [{'l2_penalty': 1, 'alpha': 0.0001, 'max_iter': 1000}]},\n",
       " {'seed': [437, 294, 9],\n",
       "  'train': [0.9653061224489796, 0.963265306122449, 0.9653061224489796],\n",
       "  'test': [0.9760765550239234, 0.9808612440191388, 0.9712918660287081],\n",
       "  'parameters': [{'l2_penalty': 1, 'alpha': 0.0001, 'max_iter': 2000}]},\n",
       " {'seed': [549, 322, 309],\n",
       "  'train': [0.9653061224489796, 0.9734693877551021, 0.9693877551020408],\n",
       "  'test': [0.9760765550239234, 0.9569377990430622, 0.9665071770334929],\n",
       "  'parameters': [{'l2_penalty': 10, 'alpha': 0.001, 'max_iter': 1000}]},\n",
       " {'seed': [202, 437, 294],\n",
       "  'train': [0.9673469387755103, 0.9653061224489796, 0.963265306122449],\n",
       "  'test': [0.9665071770334929, 0.9760765550239234, 0.9808612440191388],\n",
       "  'parameters': [{'l2_penalty': 10, 'alpha': 0.001, 'max_iter': 2000}]},\n",
       " {'seed': [9, 549, 322],\n",
       "  'train': [0.9653061224489796, 0.9653061224489796, 0.9734693877551021],\n",
       "  'test': [0.9712918660287081, 0.9760765550239234, 0.9569377990430622],\n",
       "  'parameters': [{'l2_penalty': 10, 'alpha': 0.0001, 'max_iter': 1000}]},\n",
       " {'seed': [309, 202, 437],\n",
       "  'train': [0.9693877551020408, 0.9673469387755103, 0.9653061224489796],\n",
       "  'test': [0.9665071770334929, 0.9665071770334929, 0.9760765550239234],\n",
       "  'parameters': [{'l2_penalty': 10, 'alpha': 0.0001, 'max_iter': 2000}]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_1 = LogisticRegression(use_adaptive_alpha=False)\n",
    "\n",
    "# Creating a new model with the required parameters\n",
    "logistic_1_parameters = {'l2_penalty': [1, 10],\n",
    "             'alpha': [0.001, 0.0001],\n",
    "            'max_iter': [1000, 2000]}\n",
    "\n",
    "# Performing a grid search on the model \n",
    "scores = grid_search_cv(logistic_1, breast, logistic_1_parameters, cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score obtained in the randomized search for 3 iterations: {'parameters': [{'l2_penalty': 1.0, 'alpha': 0.0007454545454545455, 'max_iter': 1120.6030150753768}, {'l2_penalty': 10.0, 'alpha': 0.0001363636363636364, 'max_iter': 1798.994974874372}, {'l2_penalty': 6.0, 'alpha': 0.0004909090909090909, 'max_iter': 1246.2311557788944}], 'seed': [512, 468, 81], 'train': [[0.9653061224489796, 0.9714285714285714, 0.963265306122449], [0.9673469387755103, 0.9714285714285714, 0.9653061224489796], [0.9755102040816327, 0.9653061224489796, 0.9673469387755103]], 'test': [[0.9760765550239234, 0.9569377990430622, 0.9808612440191388], [0.9712918660287081, 0.9617224880382775, 0.9712918660287081], [0.9521531100478469, 0.9760765550239234, 0.9712918660287081]]}\n",
      "-------------------\n",
      "Score obtained in the randomized search for 10 iterations: {'parameters': [{'l2_penalty': 10.0, 'alpha': 0.000990909090909091, 'max_iter': 1427.1356783919598}, {'l2_penalty': 1.0, 'alpha': 0.0007454545454545455, 'max_iter': 1120.6030150753768}, {'l2_penalty': 10.0, 'alpha': 0.0001363636363636364, 'max_iter': 1798.994974874372}, {'l2_penalty': 6.0, 'alpha': 0.0004909090909090909, 'max_iter': 1246.2311557788944}, {'l2_penalty': 10.0, 'alpha': 0.000990909090909091, 'max_iter': 1427.1356783919598}, {'l2_penalty': 1.0, 'alpha': 0.0007454545454545455, 'max_iter': 1120.6030150753768}, {'l2_penalty': 10.0, 'alpha': 0.0001363636363636364, 'max_iter': 1798.994974874372}, {'l2_penalty': 6.0, 'alpha': 0.0004909090909090909, 'max_iter': 1246.2311557788944}, {'l2_penalty': 10.0, 'alpha': 0.000990909090909091, 'max_iter': 1427.1356783919598}, {'l2_penalty': 1.0, 'alpha': 0.0007454545454545455, 'max_iter': 1120.6030150753768}], 'seed': [779, 512, 468, 81, 779, 512, 468, 81, 779, 512], 'train': [[0.9591836734693877, 0.9612244897959183, 0.9673469387755103], [0.9653061224489796, 0.9714285714285714, 0.963265306122449], [0.9673469387755103, 0.9714285714285714, 0.9653061224489796], [0.9755102040816327, 0.9653061224489796, 0.9673469387755103], [0.9591836734693877, 0.9612244897959183, 0.9673469387755103], [0.9653061224489796, 0.9714285714285714, 0.963265306122449], [0.9673469387755103, 0.9714285714285714, 0.9653061224489796], [0.9755102040816327, 0.9653061224489796, 0.9673469387755103], [0.9591836734693877, 0.9612244897959183, 0.9673469387755103], [0.9653061224489796, 0.9714285714285714, 0.963265306122449]], 'test': [[0.9904306220095693, 0.9856459330143541, 0.9712918660287081], [0.9760765550239234, 0.9569377990430622, 0.9808612440191388], [0.9712918660287081, 0.9617224880382775, 0.9712918660287081], [0.9521531100478469, 0.9760765550239234, 0.9712918660287081], [0.9904306220095693, 0.9856459330143541, 0.9712918660287081], [0.9760765550239234, 0.9569377990430622, 0.9808612440191388], [0.9712918660287081, 0.9617224880382775, 0.9712918660287081], [0.9521531100478469, 0.9760765550239234, 0.9712918660287081], [0.9904306220095693, 0.9856459330143541, 0.9712918660287081], [0.9760765550239234, 0.9569377990430622, 0.9808612440191388]]}\n"
     ]
    }
   ],
   "source": [
    "logistic_2 = LogisticRegression(use_adaptive_alpha=False)\n",
    "\n",
    "# Creating a new model but adding \n",
    "logistic_2_parameters = {'l2_penalty': np.linspace(1, 10, 10),\n",
    "             'alpha': np.linspace(0.001, 0.0001, 100),\n",
    "            'max_iter': np.linspace(1000, 2000, 200)}\n",
    "\n",
    "# Performing a random search cross validation for 3 iterations\n",
    "scores_1 = randomized_search_cv(logistic_2, breast, logistic_2_parameters, n_iter = 3)\n",
    "print(\"Score obtained in the randomized search for 3 iterations:\\n\", scores_1)\n",
    "print('-------------------')\n",
    "\n",
    "# Performing a random search cross validation for 10 iterations\n",
    "scores_2 = randomized_search_cv(logistic_2, breast, logistic_2_parameters)\n",
    "print(\"Score obtained in the randomized search for 10 iterations:\\n\", scores_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "61bd4cd6a51e1248a16ff8ae8fb80f3268d865b218e328ad68c6b6d874359644"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
