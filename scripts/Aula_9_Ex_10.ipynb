{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 10: Redes neuronais, layers de ativação, regressão e multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.neural_networks.layers import Dense, SigmoidActivation, SoftMaxActivation, ReLUActivation, LinearActivation\n",
    "from si.neural_networks.nn import NN\n",
    "from si.data.dataset import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.1) Adiciona uma nova layer de ativação chamada SoftMaxActivation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.2) Adiciona uma nova layer de ativação chamada ReLUActivation\n",
    "\n",
    "- Esta layer deve calcular a relação linear retificada. Ou seja, deves considerar a parte positiva do seu argumento.\n",
    "\n",
    "- Considera a seguinte função do numpy para implementar a função ReLU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.3) Constrói um modelo de redes neuronais considerando a seguinte topologia:\n",
    "\n",
    "- O dataset de treino contém 32 features\n",
    "\n",
    "- O problema é do tipo binário\n",
    "\n",
    "- O modelo deve conter 3 Dense layers:\n",
    "\n",
    "    • Dense layer de input\n",
    "\n",
    "    • Dense layer com redução do número de neurónios (units) para metade\n",
    "    \n",
    "    • Dense layer final (output)\n",
    "\n",
    "- Usa a SigmoidActivation como layer de ativação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<si.neural_networks.nn.NN at 0x1a1e4ec93a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an adequate training dataset\n",
    "\n",
    "# Creating 100 samples with 32 features of random floats\n",
    "x = np.random.randn(100, 32) \n",
    "# Creating random binary integers labels for the 100 samples\n",
    "y = np.random.randint(0, 2, 100)\n",
    "\n",
    "dataset = Dataset(x, y)\n",
    "\n",
    "# If score is lower than 0.5 the output is 0, and if score is higher than 0.5 the output is 1\n",
    "layer_1 = Dense(input_size = 32, output_size = 16)\n",
    "layer_2 = Dense(input_size = 16, output_size = 8)\n",
    "layer_3 = Dense(input_size = 8, output_size = 4)  \n",
    "\n",
    "layer_1_sg_activation = SigmoidActivation()\n",
    "layer_2_sg_activation = SigmoidActivation()\n",
    "layer_3_sg_activation= SigmoidActivation()\n",
    "\n",
    "# Between the layers, we have the layer activation\n",
    "nn_model = NN(layers=[layer_1, layer_1_sg_activation, layer_2, layer_2_sg_activation, layer_3, layer_3_sg_activation])\n",
    "# Training the neural network\n",
    "nn_model.fit(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.4) Constrói um modelo de redes neuronais considerando a seguinte topologia:\n",
    "\n",
    "- O dataset de treino contém 32 features\n",
    "\n",
    "- O problema é do tipo multiclass com 3 classes\n",
    "\n",
    "- O modelo deve conter 3 Dense layers:\n",
    "\n",
    "    • Dense layer de input \n",
    "    \n",
    "    • Dense layer com redução do número de neurónios (units) para metade \n",
    "    \n",
    "    • Dense layer final (output)\n",
    "\n",
    "- Usa a SigmoidActivation como layer de ativação\n",
    "\n",
    "- Usa a SoftMaxActivation como última layer de ativação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<si.neural_networks.nn.NN at 0x1a1e4811ac0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an adequate training dataset\n",
    "\n",
    "# Creating 100 samples with 32 features of random floats\n",
    "x1 = np.random.randn(100, 32)  \n",
    "# Creating random binary integers labels for the 100 samples\n",
    "y1 = np.random.randint(0, 3, 100) \n",
    "\n",
    "dataset_1 = Dataset(x1, y1)\n",
    "\n",
    "layer_1 = Dense(input_size = 32, output_size = 16)\n",
    "layer_2 = Dense(input_size = 16, output_size = 8)\n",
    "# With this will assign each output to the corresponding class according to the score\n",
    "layer_3 = Dense(input_size = 8, output_size = 4) \n",
    "\n",
    "layer_1_sg_activation = SigmoidActivation()\n",
    "layer_2_sg_activation= SigmoidActivation()\n",
    "# By doing this we will assign a probability to each class that summed together will add up to 1\n",
    "layer_3_sm_activation = SoftMaxActivation()  \n",
    "\n",
    "# Between layers, we have the layer activation\n",
    "nn_model_1 = NN(layers=[layer_1, layer_1_sg_activation, layer_2, layer_2_sg_activation, layer_3, layer_3_sm_activation])\n",
    "# Training the neural network\n",
    "nn_model_1.fit(dataset_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.5) Constrói um modelo de redes neuronais considerando a seguinte topologia:\n",
    "\n",
    "- O dataset de treino contém 32 features\n",
    "\n",
    "- O problema é do tipo regressão\n",
    "\n",
    "- O modelo deve conter 3 Dense layers:\n",
    "\n",
    "    • Dense layer de input \n",
    "    \n",
    "    • Dense layer com redução do número de neurónios (units) para metade \n",
    "    \n",
    "    • Dense layer final (output)\n",
    "\n",
    "- Usa a ReLU como layer de ativação\n",
    "\n",
    "- Considera que o modelo deve acabar com uma ativação linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<si.neural_networks.nn.NN at 0x1a1e24aae20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an adequate training dataset\n",
    "\n",
    "# Creating 100 samples with 32 features of random floats\n",
    "x2 = np.random.randn(100, 32)  \n",
    "# Creating labels for the 100 samples of random floats\n",
    "y2 = np.random.randn(100) \n",
    "\n",
    "# Creating a new dataset\n",
    "dataset_2 = Dataset(x2, y2)\n",
    "\n",
    "layer_1 = Dense(input_size = 32, output_size = 16)\n",
    "layer_2 = Dense(input_size = 16, output_size = 8)\n",
    "# Returns a single continuous target for each sample\n",
    "layer_3 = Dense(input_size = 8, output_size = 4) \n",
    "\n",
    "layer_1_rl_activation = ReLUActivation()\n",
    "layer_2_rl_activation = ReLUActivation()\n",
    "# Returns real values as an output\n",
    "layer_3_l_activation = LinearActivation() \n",
    "\n",
    "# Between the layers, we have the layer activation\n",
    "nn_model_2 = NN(layers = [layer_1, layer_1_rl_activation, layer_2, layer_2_rl_activation, layer_3, layer_3_l_activation])\n",
    "# Training the neural network\n",
    "nn_model_2.fit(dataset_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26683c0a52c1ce81576e6920e98984204be89e95651716e71c2eb5e64142253a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
