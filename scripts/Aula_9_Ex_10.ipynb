{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 10: Redes neuronais, layers de ativação, regressão e multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.neural_networks.layers import Dense, SigmoidActivation, SoftMaxActivation, ReLUActivation, LinearActivation\n",
    "from si.neural_networks.nn import NN\n",
    "from si.data.dataset import Dataset\n",
    "from si.model_selection.split import train_test_split\n",
    "from si.io.csv import read_csv\n",
    "from si.metrics.cross_entropy import cross_entropy, cross_entropy_derivative\n",
    "from si.metrics.accuracy import accuracy\n",
    "from si.metrics.mse import mse, mse_derivative\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.1) Adiciona uma nova layer de ativação chamada SoftMaxActivation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.2) Adiciona uma nova layer de ativação chamada ReLUActivation\n",
    "\n",
    "- Esta layer deve calcular a relação linear retificada. Ou seja, deves considerar a parte positiva do seu argumento.\n",
    "\n",
    "- Considera a seguinte função do numpy para implementar a função ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.3) Constrói um modelo de redes neuronais considerando a seguinte topologia:\n",
    "\n",
    "- O dataset de treino contém 32 features\n",
    "\n",
    "- O problema é do tipo binário\n",
    "\n",
    "- O modelo deve conter 3 Dense layers:\n",
    "\n",
    "    • Dense layer de input\n",
    "\n",
    "    • Dense layer com redução do número de neurónios (units) para metade\n",
    "    \n",
    "    • Dense layer final (output)\n",
    "\n",
    "- Usa a SigmoidActivation como layer de ativação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([1, 0, 0, 1])\n",
    "dataset = Dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If score is lower than 0.5 the output is 0, and if score is higher than 0.5 the output is 1\n",
    "layer_1 = Dense(input_size = 2, output_size = 2)\n",
    "layer_2 = Dense(input_size = 2, output_size = 1)\n",
    "\n",
    "layer_1_sg_activation = SigmoidActivation()\n",
    "layer_2_sg_activation = SigmoidActivation()\n",
    "\n",
    "# Between the layers, we have the layer activation\n",
    "nn_model = NN(layers=[layer_1, layer_1_sg_activation, layer_2, layer_2_sg_activation])\n",
    "# Training the neural network\n",
    "nn_model.fit(dataset)\n",
    "nn_model.predict(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.4) Constrói um modelo de redes neuronais considerando a seguinte topologia:\n",
    "\n",
    "- O dataset de treino contém 32 features\n",
    "\n",
    "- O problema é do tipo multiclass com 3 classes\n",
    "\n",
    "- O modelo deve conter 3 Dense layers:\n",
    "\n",
    "    • Dense layer de input \n",
    "    \n",
    "    • Dense layer com redução do número de neurónios (units) para metade \n",
    "    \n",
    "    • Dense layer final (output)\n",
    "\n",
    "- Usa a SigmoidActivation como layer de ativação\n",
    "\n",
    "- Usa a SoftMaxActivation como última layer de ativação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an adequate training dataset\n",
    "\n",
    "# Creating 100 samples with 32 features of random floats\n",
    "x1 = np.random.randn(100, 32)  \n",
    "# Creating random binary integers labels for the 100 samples\n",
    "y1 = np.random.randint(0, 3, 100) \n",
    "\n",
    "dataset_1 = Dataset(x1, y1)\n",
    "\n",
    "layer_1 = Dense(input_size = 32, output_size = 32)\n",
    "layer_2 = Dense(input_size = 32, output_size = 16)\n",
    "# With this will assign each output to the corresponding class according to the score\n",
    "layer_3 = Dense(input_size = 16, output_size = 1) \n",
    "\n",
    "layer_1_sg_activation = SigmoidActivation()\n",
    "layer_2_sg_activation= SigmoidActivation()\n",
    "# By doing this we will assign a probability to each class that summed together will add up to 1\n",
    "layer_3_sm_activation = SigmoidActivation ()\n",
    "\n",
    "# Between layers, we have the layer activation\n",
    "nn_model_1 = NN(layers=[layer_1, layer_1_sg_activation, layer_2, layer_2_sg_activation, layer_3, layer_3_sm_activation])\n",
    "# Training the neural network\n",
    "nn_model_1.fit(dataset_1)\n",
    "nn_model_1.predict(dataset_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.5) Constrói um modelo de redes neuronais considerando a seguinte topologia:\n",
    "\n",
    "- O dataset de treino contém 32 features\n",
    "\n",
    "- O problema é do tipo regressão\n",
    "\n",
    "- O modelo deve conter 3 Dense layers:\n",
    "\n",
    "    • Dense layer de input \n",
    "    \n",
    "    • Dense layer com redução do número de neurónios (units) para metade \n",
    "    \n",
    "    • Dense layer final (output)\n",
    "\n",
    "- Usa a ReLU como layer de ativação\n",
    "\n",
    "- Considera que o modelo deve acabar com uma ativação linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an adequate training dataset\n",
    "\n",
    "# Creating 100 samples with 32 features of random floats\n",
    "x = np.random.randn(0, 3, 100)  \n",
    "\n",
    "# Creating a new dataset\n",
    "dataset_2 = Dataset(x2, x)\n",
    "\n",
    "layer_1 = Dense(input_size = 32, output_size = 16)\n",
    "layer_2 = Dense(input_size = 16, output_size = 8)\n",
    "# Returns a single continuous target for each sample\n",
    "layer_3 = Dense(input_size = 8, output_size = 4) \n",
    "\n",
    "layer_1_rl_activation = ReLUActivation()\n",
    "layer_2_rl_activation = ReLUActivation()\n",
    "# Returns real values as an output\n",
    "layer_3_l_activation = LinearActivation() \n",
    "\n",
    "# Between the layers, we have the layer activation\n",
    "nn_model_2 = NN(layers = [layer_1, layer_1_rl_activation, layer_2, layer_2_rl_activation, layer_3, layer_3_l_activation])\n",
    "# Training the neural network\n",
    "nn_model_2.fit(dataset_2)\n",
    "nn_model_2.predict(dataset_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26683c0a52c1ce81576e6920e98984204be89e95651716e71c2eb5e64142253a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
