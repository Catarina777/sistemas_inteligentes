{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 6: Adiciona o modelo ensemble StackingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1) Considera a estrutura do StackingClassifier apresentada nos slides seguintes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2) Valida a tua implementação seguindo o protocolo:\n",
    "\n",
    "1. Usa o dataset breast-bin.csv\n",
    "\n",
    "2. Usa o sklearn.preprocessing.StandardScaler para standardizar os dataset. breast_dataset.X = StandardScaler().fit_transform(breast_dataset.X)\n",
    "\n",
    "3. Divide o dataset em treino e teste\n",
    "\n",
    "4. Cria o modelo KNNClassifier\n",
    "\n",
    "5. Cria o modelo LogisticRegression\n",
    "\n",
    "6. Cria um segundo modelo KNNClassifier (modelo final)\n",
    "\n",
    "7. Cria o modelo StackingClassifier usando os classificadores anteriores. O segundo modelo KNNClassifier deve ser usado como modelo final.\n",
    "8. Treina o modelo. Qual o score obtido?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.ensemble.voting_classifier import VotingClassifier\n",
    "from si.ensemble.stacking_classifier import StackingClassifier\n",
    "from si.io.data_file import read_data_file\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from si.model_selection.split import train_test_split\n",
    "from si.linear_module.logistic_regression import LogisticRegression\n",
    "from si.neighbours.knn_classifier import KNNClassifier\n",
    "from si.statistics.euclidean_distance import euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data file to the notebook\n",
    "path = 'C:/Users/Catarina Ferreira/Desktop/Bioinf 2ºano/sistemas_inteligentes/datasets/breast-bin.data'\n",
    "# Reading the data file\n",
    "breast = read_data_file(path, sep=\",\", label=True)\n",
    "\n",
    "# Standardizing and transforming the values\n",
    "breast.x = StandardScaler().fit_transform(breast.x)\n",
    "# Spliting the dataset in train and testing parts\n",
    "train, test = train_test_split(breast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predicted values:\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "--------------------\n",
      "Score: 97.60765550239235\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(use_adaptive_alpha = False, max_iter=3000)\n",
    "# Predicting classes\n",
    "knn = KNNClassifier(k=4, distance = euclidean_distance)\n",
    "\n",
    "vote = VotingClassifier([log, knn])\n",
    "vote.fit(train)\n",
    "\n",
    "# Printing the predicted values of the test\n",
    "print(\"Test predicted values:\\n\", vote.predict(test))\n",
    "print('--------------------')\n",
    "# Printing the accuracy of the model\n",
    "scores = vote.score(test)\n",
    "print(\"Score:\", scores*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predicted values:\n",
      " [0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1.\n",
      " 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "--------------------\n",
      "Score: 96.17224880382776\n"
     ]
    }
   ],
   "source": [
    "# Predicting classes for a new model\n",
    "f_model = KNNClassifier(k=5, distance = euclidean_distance)\n",
    "# Generating a prediction for the new model\n",
    "stack = StackingClassifier([log, knn], f_model)\n",
    "stack.fit(train)\n",
    "\n",
    "# Printing the predicted values of the test\n",
    "print(\"Test predicted values:\\n\",stack.predict(test))\n",
    "print('--------------------')\n",
    "# Printing the accuracy of the model\n",
    "scores = stack.score(test)\n",
    "print(\"Score:\", scores*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26683c0a52c1ce81576e6920e98984204be89e95651716e71c2eb5e64142253a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
